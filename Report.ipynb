{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "############# MSc Artificial Intelligence ##############\n",
    "#### INM706-Deep Learning for Sequence Analysis ########\n",
    "#### AUTHORS: Vittoria Castelnuovo, Tommaso Capecchi ####\n",
    "########################################################\n",
    "\n",
    "import re\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from dataset import CornellCorpus\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model import Encoder, Decoder, ChatbotModel, EncoderAttention, DecoderAttention, Attention, GreedySearch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "from nltk.translate import bleu_score\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# check cuda availability\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "print(device)\n",
    "\n",
    "# define the dir where to save the trained model\n",
    "save_model_dir = 'saved_models'\n",
    "if not os.path.exists(save_model_dir):\n",
    "    os.mkdir(save_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define some useful functions\n",
    "\n",
    "def get_movie_lines(path):\n",
    "    \"\"\"\n",
    "    This function extracts the movie lines id and the text associated\n",
    "    and store them in a dictionary.\n",
    "    :param path: the path where to find the file 'movie_lines.txt'\n",
    "    :return line_to_phrase: the dictionary that maps each line id to the corresponding text\n",
    "    \"\"\"\n",
    "    file = open(path, 'r', encoding='iso-8859-1')\n",
    "    dialog_data = []\n",
    "    line_to_phrase = {}\n",
    "    for line in file.readlines():\n",
    "        dialog_data.append(line.strip().split(sep=' +++$+++ '))\n",
    "    for information in dialog_data:\n",
    "        line_to_phrase[information[0]] = information[-1].replace('\\n', '')\n",
    "    return line_to_phrase\n",
    "\n",
    "\n",
    "def extract_dialogs():\n",
    "    \"\"\"\n",
    "    This function extracts dialogs from each movie. A dialog is represented by\n",
    "    a list on lineid which identifies a unique conversation in the dataset.\n",
    "    :return conversation:\n",
    "    \"\"\"\n",
    "    PATH_CONVERSATION = os.path.join(os.curdir, 'cornell-movie-dialogs-corpus/movie_conversations.txt')\n",
    "    file = open(PATH_CONVERSATION, 'r', encoding='iso-8859-1')\n",
    "    dialog_list = []\n",
    "\n",
    "    # extract conversations info from 'movie_conversation.txt'\n",
    "    for line in file.readlines():\n",
    "        line = line.split(' +++$+++ ')\n",
    "        regex = re.compile('[^a-zA-Z0-9.,!?]')\n",
    "        line = regex.sub('', line[-1])\n",
    "        line = line.split(',')\n",
    "        dialog_list.append(line)\n",
    "\n",
    "    return dialog_list\n",
    "\n",
    "\n",
    "def create_pair_dialogs(dialogs):\n",
    "    \"\"\"\n",
    "    This function creates each conversation pair [[Question],[Answer]]\n",
    "    :param dialogs: the set of dialogs to process\n",
    "    :return: the list of pairs Q&A\n",
    "    \"\"\"\n",
    "    # dictionary that stores the following [question] -> [answer] for each line in a dialog\n",
    "    dialogs_pairs = []\n",
    "    for dialog in dialogs:\n",
    "        for idx in range(len(dialog) - 1):\n",
    "            question_to_answer = []\n",
    "            question_to_answer.append(dialog[idx])\n",
    "            question_to_answer.append(dialog[idx+1])\n",
    "            # check if either the answer or the question is empty and if that's the case don't append it.\n",
    "            if dialog[idx] and dialog[idx+1]:\n",
    "                dialogs_pairs.append(question_to_answer)\n",
    "    return dialogs_pairs\n",
    "\n",
    "\n",
    "def format_time(start, end):\n",
    "    \"\"\"\n",
    "    Computes the interval time between a start and an end point.\n",
    "    :param start: starting time\n",
    "    :param end: ending time\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    elapsed_time = end - start\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_secs, elapsed_mins\n",
    "\n",
    "def pad_sequence(sequence, max_length):\n",
    "    \"\"\"\n",
    "    This function pads each sentence after the EOS by inserting 0s\n",
    "    till the max length limit is reached.\n",
    "    :param sequence: list of integers that represents a sentence\n",
    "    :param max_length: maximum length of the sentence.\n",
    "    :return: the padded sentence.\n",
    "    \"\"\"\n",
    "    pad_token_idx = vocabulary.word_to_idx['<PAD>']\n",
    "    while len(sequence) <= max_length:\n",
    "        sequence.append(pad_token_idx)\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def format_user_input(sequence, max_length=10):\n",
    "    \"\"\"\n",
    "    Normalises a sentence inserted by the user to let the chatbot\n",
    "    process the sequence of words.\n",
    "    :param sequence: the input sentence typed by the used\n",
    "    :param max_length: length limit of each sentence\n",
    "    :return: the sequence of indices that represent the user's input sentence\n",
    "    \"\"\"\n",
    "    # convert each word into index from the vocabulary\n",
    "    regex = re.compile('[^a-zA-Z0-9.!?]')\n",
    "    sequence = regex.sub(' ', sequence)\n",
    "    # remove extra space\n",
    "    sequence = re.sub(r\"([.!?'])\", r\" \\1\", sequence)\n",
    "    # remove non-letter characters but keep regular punctuation\n",
    "    sentence = re.sub(r\"[^a-zA-Z]+\", r\" \", sequence)\n",
    "    sequence = sequence.lower()\n",
    "    sequence = sequence.strip().split()\n",
    "    user_seq_indices = []\n",
    "    for word in sequence:\n",
    "        if word in vocabulary.word_to_idx.keys():\n",
    "            user_seq_indices.append(vocabulary.word_to_idx[word])\n",
    "        else:\n",
    "            user_seq_indices.append(vocabulary.word_to_idx['<UNK>'])\n",
    "\n",
    "    # pad or trim the sentence\n",
    "    if len(user_seq_indices) > max_length:  # trim\n",
    "        user_seq_indices = user_seq_indices[:max_length]\n",
    "        user_seq_indices.append(vocabulary.word_to_idx['</S>'])\n",
    "    elif len(user_seq_indices) <= max_length:  # pad\n",
    "        user_seq_indices.append(vocabulary.word_to_idx['</S>'])\n",
    "        user_seq_indices = pad_sequence(user_seq_indices, max_length)\n",
    "    user_seq_indices = torch.tensor(user_seq_indices).unsqueeze(1)\n",
    "    user_seq_indices = user_seq_indices.to(device)\n",
    "    return user_seq_indices\n",
    "\n",
    "\n",
    "def convert_to_string(reply):\n",
    "    \"\"\"\n",
    "    Convert a sentence of indices to the respective sequence of words.\n",
    "    :param reply: the list of indices that represents a sentence created by the model\n",
    "    :return: a string representation of the sentence of indices\n",
    "    \"\"\"\n",
    "    parsed_reply = []\n",
    "    for word_idx in reply:\n",
    "        # if the word is PAD or END of Sentence token, ignore it.\n",
    "        reply = vocabulary.vocab[word_idx]\n",
    "        if word_idx == vocabulary.word_to_idx['<PAD>'] or word_idx == vocabulary.word_to_idx['</S>']:\n",
    "            break\n",
    "        else:\n",
    "            parsed_reply.append(reply)\n",
    "\n",
    "    return ' '.join(parsed_reply)\n",
    "\n",
    "\n",
    "def map_to_idx(sequence):\n",
    "    \"\"\"\n",
    "    Processes a sentence by mapping each word to the respective index in the vocabulary\n",
    "    :param sequence: the sentence to be processed\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    seq_idx = []\n",
    "    for word in sequence:\n",
    "        seq_idx.append(vocabulary.word_to_idx[word])\n",
    "    return seq_idx\n",
    "\n",
    "\n",
    "def evaluate(seq, searcher):\n",
    "    \"\"\"\n",
    "    Process the user's input by getting the best guess after\n",
    "    the sentenced has been given in input to the model.\n",
    "    :param seq: the list of indices that represent the input sentence\n",
    "    :param searcher: the evaluator that process the user's input\n",
    "    :return: the phrase generated by the model.\n",
    "    \"\"\"\n",
    "    # tensor should have shape [seq, 1]\n",
    "    seq = seq.to(device)\n",
    "    # feedforward to the searcher to get the list of most likely indices of words\n",
    "    bot_reply = searcher(seq)\n",
    "    # discard first element which is the start token\n",
    "    bot_reply = bot_reply[1:].to(device)\n",
    "    bot_reply = bot_reply.topk(1).indices.reshape(1, -1).tolist()[0]\n",
    "    # convert indices to words.\n",
    "    bot_reply = convert_to_string(bot_reply)\n",
    "    return bot_reply\n",
    "\n",
    "\n",
    "def init_model(with_attention=False, teaching_force_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Instantiates the model by creating the Encoder, the Decoder and the\n",
    "    model itself which represents the seq2seq architecture.\n",
    "    :param with_attention: if true then the model apply the attention mechanism\n",
    "    :param teaching_force_ratio: used to alternate between generated word or gt-word during training.\n",
    "    :return encoder, decoder, model: the encoder, the decoder and the seq2seq model.\n",
    "    \"\"\"\n",
    "    if with_attention:\n",
    "        # init with attention\n",
    "        encoder = EncoderAttention(embedding_size, hidden_size, vocabulary.__len__()).to(device)\n",
    "        attention = Attention(hidden_size).to(device)\n",
    "        decoder = DecoderAttention(embedding_size, hidden_size, vocabulary.__len__(), attention=attention).to(\n",
    "            device)\n",
    "        model = ChatbotModel(encoder, decoder, vocabulary.__len__(), with_attention=True, tf_ratio=teaching_force_ratio).to(device)\n",
    "        return encoder, decoder, model\n",
    "    else:\n",
    "        # init with no attention\n",
    "        encoder = Encoder(embedding_size, hidden_size, vocabulary.__len__()).to(device)\n",
    "        decoder = Decoder(embedding_size, hidden_size, vocabulary.__len__()).to(device)\n",
    "        model = ChatbotModel(encoder, decoder, vocabulary.__len__(), with_attention=False,tf_ratio=teaching_force_ratio).to(device)\n",
    "        return encoder, decoder, model\n",
    "\n",
    "\n",
    "def run_bot(searcher, testing=True, max_length=10):\n",
    "    \"\"\"\n",
    "    Executes the model. The user is prompted with the sentence to\n",
    "    insert and then the sentence is processed by the model which\n",
    "    will output the corresponding reply.\n",
    "    :param searcher: the evaluator used to search for the best reply\n",
    "    :param testing: if true, a pre-setted phrase will be evaluated\n",
    "    :param max_length: limit length for each sentence to be processed\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.encoder.eval()\n",
    "    model.decoder.eval()\n",
    "    if testing:\n",
    "        user_input = 'Hey how are you?'\n",
    "        user_input_idx = format_user_input(user_input, max_length)\n",
    "        reply = evaluate(user_input_idx, searcher)\n",
    "        print(reply)\n",
    "    else:\n",
    "        while(True):\n",
    "            try:\n",
    "                # ask the user for the input\n",
    "                user_input = input('> ')\n",
    "                # format the user input.\n",
    "                if user_input == 'quit':\n",
    "                    break\n",
    "                user_input_idx = format_user_input(user_input, max_length)\n",
    "                # run the evaluate function to get bot's reply\n",
    "                reply = evaluate(user_input_idx, searcher)\n",
    "                print(reply)\n",
    "            except KeyError:\n",
    "                print('Error: While parsing the input sentence...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the Vocabulary class\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"\n",
    "    This class implements the vocabulary used to store\n",
    "    all the words extracted from the Dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, idx_to_text, dialogs_ids):\n",
    "        self.dialogs_ids = dialogs_ids\n",
    "        self.idx_to_text = self.normalize_sentence(idx_to_text)\n",
    "        # maps each word to a unique integer\n",
    "        self.word_to_idx = self.map_word_to_idx()\n",
    "        # maps each unique index to the corresponding word\n",
    "        self.vocab = self.map_idx_to_word()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    def normalize_sentence(self, idx_to_text):\n",
    "        \"\"\"\n",
    "        Process each movie line so that each movie\n",
    "        dialog contains only characters. Empty sentences\n",
    "        are filtered\n",
    "        :param idx_to_text: maps each movie line to the corresponding sentece\n",
    "        :return: normalized dictionary that maps each movie ID to its sentence\n",
    "        \"\"\"\n",
    "        normalized_idx_to_sentence = {}\n",
    "        for line_id, sentence in zip(idx_to_text.keys(), idx_to_text.values()):\n",
    "            # convert each word in the sentence to a lower case\n",
    "            sentence = sentence.lower()\n",
    "            # eliminate extra spaces for punctuation\n",
    "            sentence = re.sub(r\"([.,!?'])\", r\" \\1\", sentence)\n",
    "            # remove non-letter characters but keep regular punctuation\n",
    "            sentence = re.sub(r\"[^a-zA-Z]+\", r\" \", sentence)\n",
    "            normalized_idx_to_sentence[line_id] = sentence\n",
    "\n",
    "        # filters empty q-a pairs\n",
    "        filtered_sentences = {}\n",
    "        for line_id, text in zip(normalized_idx_to_sentence.keys(), normalized_idx_to_sentence.values()):\n",
    "            if text != ' ':\n",
    "                filtered_sentences[line_id] = text\n",
    "        print('Filtered sentences: {}'.format(len(normalized_idx_to_sentence) - len(filtered_sentences)))\n",
    "        return normalized_idx_to_sentence\n",
    "\n",
    "    def map_idx_to_word(self):\n",
    "        \"\"\"\n",
    "        Assign to each word a unique numeric value, so that\n",
    "        an integer is mapped to a unique word\n",
    "        :return: an ordered dictionary with the corresponding mapping\n",
    "        \"\"\"\n",
    "        words = self.word_to_idx.keys()\n",
    "        index = self.word_to_idx.values()\n",
    "        idx_to_word = OrderedDict()\n",
    "        for w, i in zip(words, index):\n",
    "            idx_to_word[i] = w\n",
    "        return idx_to_word\n",
    "\n",
    "    def map_word_to_idx(self):\n",
    "        \"\"\"\n",
    "        Maps each word to a unique index to create a vocabulary.\n",
    "        The SOS, EOS, UNK, PAD tokens are also inserted into the data structure.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        word_to_idx = {}\n",
    "        count_words = 0\n",
    "        for dialogs in self.dialogs_ids:\n",
    "            for line in dialogs:\n",
    "                sentence = self.idx_to_text[line]\n",
    "                for word in sentence.strip().split():\n",
    "                    if word not in word_to_idx:\n",
    "                        word_to_idx[word] = count_words\n",
    "                        count_words += 1\n",
    "        start_token = '<S>'\n",
    "        end_token = '</S>'\n",
    "        unknown_token = '<UNK>'\n",
    "        pad_token = '<PAD>'\n",
    "        word_to_idx = sorted(word_to_idx)\n",
    "        word_to_idx.insert(0, unknown_token)\n",
    "        word_to_idx.insert(0, end_token)\n",
    "        word_to_idx.insert(0, start_token)\n",
    "        word_to_idx.insert(0, pad_token)\n",
    "        word_to_idx = self.build_dictionary(word_to_idx)\n",
    "        return word_to_idx\n",
    "\n",
    "    def build_dictionary(self, word_collection):\n",
    "        \"\"\"\n",
    "        Create the ordered dictionary from the mapping dictionary {word:id}.\n",
    "        :param word_collection: a dictionary that stores the association between word:id\n",
    "        :return: the dictionary represented as OrderedDict\n",
    "        \"\"\"\n",
    "        word_to_idx = OrderedDict()\n",
    "        for idx, word in enumerate(word_collection):\n",
    "            word_to_idx[word] = idx\n",
    "        return word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered sentences: 64\n",
      "Total words counted in the vocabulary: 48091\n",
      "Total training batches: 177226, Total val batches: 22151, Total test batches: 22149\n"
     ]
    }
   ],
   "source": [
    "dirs = os.path.join(os.curdir, 'cornell-movie-dialogs-corpus/movie_lines.txt')\n",
    "idx_to_text = get_movie_lines(dirs)\n",
    "# create a list of dialogs for each movie.\n",
    "dialogs = extract_dialogs()\n",
    "# for each movie, create pairs dialogs (Q/A). This is the actual data used for training.\n",
    "pair_dialogs_idx = create_pair_dialogs(dialogs)\n",
    "# instantiate the vocabulary\n",
    "vocabulary = Vocabulary(idx_to_text, dialogs)\n",
    "print('Total words counted in the vocabulary: {}'.format(vocabulary.__len__()))\n",
    "\n",
    "# shuffle data\n",
    "np.random.shuffle(pair_dialogs_idx)\n",
    "train_data = CornellCorpus(pair_dialogs_idx, vocabulary, max_length=10, stage='train')\n",
    "val_data = CornellCorpus(pair_dialogs_idx, vocabulary, max_length=10, stage='val')\n",
    "test_data = CornellCorpus(pair_dialogs_idx, vocabulary, max_length=10, stage='test')\n",
    "\n",
    "print('Total training batches: {}, Total val batches: {}, Total test batches: {}'.format(train_data.__len__(),\n",
    "                                                                                         val_data.__len__(),\n",
    "                                                                                         test_data.__len__()))\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 64\n",
    "hidden_size = 256\n",
    "embedding_size = 500\n",
    "\n",
    "\n",
    "# init dataloader\n",
    "load_args = {'batch_size': batch_size, 'shuffle': True}\n",
    "train_dataloader = DataLoader(train_data, **load_args)\n",
    "val_dataloader = DataLoader(val_data, **load_args)\n",
    "load_args_test = {'batch_size': 1, 'shuffle': True}\n",
    "test_dataloader = DataLoader(test_data, **load_args_test)\n",
    "\n",
    "# init model\n",
    "encoder, decoder, model = init_model(with_attention=True)\n",
    "\n",
    "# init loss function\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocabulary.word_to_idx['</S>'])\n",
    "epoch_history = []\n",
    "\n",
    "# init evaluator --> if attention=True, then also the model requires with_attention=True\n",
    "searcher = GreedySearch(encoder, decoder, vocabulary, attention=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Sample Datapoint - 1 ####\n",
      "Question: [1, 20447, 12056, 2, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Answer: [1, 22449, 47811, 46371, 47825, 2179, 2, 0, 0, 0, 0, 0]\n",
      "\n",
      "#### Sample Datapoint - 2 ####\n",
      "Question: [1, 21883, 42754, 47825, 28436, 12529, 41281, 2, 0, 0, 0, 0]\n",
      "Answer: [1, 46597, 42634, 42592, 36386, 17956, 1394, 42592, 36386, 4, 17956, 2]\n",
      "\n",
      "#### Sample Datapoint - 3 ####\n",
      "Question: [1, 28488, 47811, 11319, 4, 29004, 2, 0, 0, 0, 0, 0]\n",
      "Answer: [1, 27047, 19622, 25003, 28870, 14172, 11552, 2, 0, 0, 0, 0]\n",
      "\n",
      "#### Sample Datapoint - 4 ####\n",
      "Question: [1, 46718, 42604, 19204, 21883, 42592, 35331, 19566, 14612, 21933, 36386, 2]\n",
      "Answer: [1, 47811, 26958, 42604, 17630, 29422, 10372, 14172, 42793, 42659, 46631, 2]\n",
      "\n",
      "#### Sample Datapoint - 5 ####\n",
      "Question: [1, 28689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Answer: [1, 20447, 10100, 24279, 47811, 43151, 37380, 42754, 2, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visualize sample of processed sentences.\n",
    "dataiter = iter(train_dataloader)\n",
    "sample_data = []\n",
    "for idx in range(5):\n",
    "    batch_idx, data = dataiter.__next__()\n",
    "    print(\"#### Sample Datapoint - {} ####\".format(idx+1))\n",
    "    print(\"Question: {}\".format(data[0].tolist()))\n",
    "    print(\"Answer: {}\".format(data[1].tolist()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 70\n",
    "def train_loop():\n",
    "    \"\"\"\n",
    "    The training loop used to train the model. At each iteration a mini-batch\n",
    "    of a predefined size N is loaded and processed. The shape of each mini-batch of data point\n",
    "    is [batch_size, max_len]. Each batch is transposed so that by accessing the values\n",
    "    by the first dimension we can process all the indices at time step t of the entire batch.\n",
    "    To keep track of the intermediate results we print\n",
    "    every 500 iterations the running loss.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    batch_history = []\n",
    "    model.encoder.train()\n",
    "    model.decoder.train()\n",
    "    avg_loss = 0\n",
    "    # start timer\n",
    "    start_time = time.time()\n",
    "    for idx, X in enumerate(train_dataloader):\n",
    "        # default previous weights values\n",
    "        model.encoder.optim.zero_grad()\n",
    "        model.decoder.optim.zero_grad()\n",
    "\n",
    "        # transpose both input sentence and target sentence to access\n",
    "        # the the i-th word for each batch at each given time step t.\n",
    "        question = torch.transpose(X[0].to(device), 0, 1)\n",
    "        answer = torch.transpose(X[1].to(device), 0, 1)\n",
    "        # compute the output. Recall the output size should be (seq_len, batch_size, voc_size)\n",
    "        output = model(question, answer)\n",
    "\n",
    "        # don't consider the first element in all batches because it's the '<S>' token\n",
    "        output = output[1:].to(device)\n",
    "        answer = answer[1:].to(device)\n",
    "        # reshape output so that we can comput the loss. The CrossEntropyLoss class\n",
    "        # expects the input to be [N, n_classes] for the predictions.\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        answer = answer.reshape(-1)\n",
    "        # compute loss\n",
    "        loss = criterion(output, answer)\n",
    "        # backpropagate to compute gradients\n",
    "        loss.backward()\n",
    "        # clip gradients to avoid exploding values\n",
    "        torch.nn.utils.clip_grad_norm_(model.encoder.parameters(), max_norm=50)\n",
    "        torch.nn.utils.clip_grad_norm_(model.decoder.parameters(), max_norm=50)\n",
    "        # perform weights update\n",
    "        model.encoder.optim.step()\n",
    "        model.decoder.optim.step()\n",
    "        # normalize loss by the length of the sentence\n",
    "        batch_history.append(loss.item()/ question.shape[0])\n",
    "        # print current loss every 500 processed batches\n",
    "        if idx % 500 == 0:\n",
    "            # end of epoch\n",
    "            end_time = time.time()\n",
    "            # format elapsed time\n",
    "            elapsed_secs, elapsed_mins = format_time(start_time, end_time)\n",
    "            print('BATCH [{}/{}], LOSS TRAINING: {}, eta: {}m {}s'.format(idx,\n",
    "                                                                          train_dataloader.__len__(),\n",
    "                                                                          loss,\n",
    "                                                                          elapsed_mins,\n",
    "                                                                          elapsed_secs))\n",
    "            # start timer\n",
    "            start_time = time.time()\n",
    "    avg_loss = np.mean(batch_history)\n",
    "    return avg_loss\n",
    "\n",
    "def val_loop():\n",
    "    \"\"\"\n",
    "    The validation loop used to keep track of the model performance during training. At each iteration a mini-batch\n",
    "    of a predefined size N is loaded and processed. The shape of each mini-batch of data point\n",
    "    is [batch_size, max_len]. Each batch is transposed so that by accessing the values\n",
    "    by the first dimension we can process all the indices at time step t of the entire batch.\n",
    "    To keep track of the intermediate results we print\n",
    "    every 500 iterations the running loss.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.encoder.eval()\n",
    "    model.decoder.eval()\n",
    "    batch_history = []\n",
    "    avg_loss = 0\n",
    "    for idx, X in enumerate(val_dataloader):\n",
    "        # transpose both input sentence and target sentence to access using the first dimension\n",
    "        # the the i-th word for each batch at each given time step t.\n",
    "        question = torch.transpose(X[0].to(device), 0, 1)\n",
    "        answer = torch.transpose(X[1].to(device), 0, 1)\n",
    "        # compute the output. Recall the output size should be (seq_len, batch_size, voc_size)\n",
    "        output = model(question, answer)\n",
    "        # don't consider the first element in all batches because it's the '<S>' token\n",
    "        output = output[1:].to(device)\n",
    "        answer = answer[1:].to(device)\n",
    "        # reshape both question and answer to the correct size for the loss function\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        answer = answer.reshape(-1)\n",
    "        # compute the loss\n",
    "        loss = criterion(output, answer)\n",
    "\n",
    "        # keep track of the loss\n",
    "        batch_history.append(loss.item()/ question.shape[0])\n",
    "    avg_loss = np.mean(batch_history)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model found. Loading...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "### TRAIN LOOP ###\n",
    "\n",
    "epoch_idx = 0\n",
    "train_history = []\n",
    "val_history = []\n",
    "if model.attention:\n",
    "    checkpoint_path = os.path.join(os.curdir, 'saved_models/checkpoint.pth')\n",
    "    path_saved_model = os.path.join(os.curdir, 'saved_models/trained_model.pth')\n",
    "else:\n",
    "    checkpoint_path = os.path.join(os.curdir, 'saved_models/checkpoint_no_att.pth')\n",
    "    path_saved_model = os.path.join(os.curdir, 'saved_models/trained_model_no_att.pth')\n",
    "    # check if the model is already trained\n",
    "if os.path.exists(path_saved_model):\n",
    "    # load state_dict\n",
    "    print('Trained model found. Loading...')\n",
    "    model.load_state_dict(torch.load(path_saved_model, map_location=torch.device(device)))\n",
    "    print('Model loaded.')\n",
    "else:\n",
    "    # check if a training phase was already started\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        # load trained values\n",
    "        loaded_checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "        print('Checkpoint found. Restore from [{}/{}] epoch.'.format(loaded_checkpoint['epoch'], epochs))\n",
    "        # restore previous values\n",
    "        epoch_idx = loaded_checkpoint['epoch']\n",
    "        model.load_state_dict(loaded_checkpoint['model_sd'])\n",
    "        model.encoder.optim.load_state_dict(loaded_checkpoint['optim_sd_encoder'])\n",
    "        model.decoder.optim.load_state_dict(loaded_checkpoint['optim_sd_decoder'])\n",
    "        train_history = loaded_checkpoint['train_history']\n",
    "        val_history = loaded_checkpoint['val_history']\n",
    "\n",
    "    # UNCOMMENT THE BELOW TO CONTINUE TRAINING\n",
    "\n",
    "    print('Start training...')\n",
    "    for epoch in range(epoch_idx, epochs):\n",
    "        # start counting epoch time\n",
    "        start_time = time.time()\n",
    "        # compute train loss\n",
    "        train_loss = train_loop()\n",
    "        train_history.append(train_loss)\n",
    "        # compute val loss\n",
    "        val_loss = val_loop()\n",
    "        val_history.append(val_loss)\n",
    "        # store train and val loss for later analysis\n",
    "        epoch_history.append((train_loss, val_loss))\n",
    "        # end of epoch\n",
    "        end_time = time.time()\n",
    "        # format elapsed time\n",
    "        elapsed_secs, elapsed_mins = format_time(start_time, end_time)\n",
    "        checkpoint = {'epoch': epoch+1,\n",
    "                      'model_sd': model.state_dict(),\n",
    "                      'optim_sd_encoder': model.encoder.optim.state_dict(),\n",
    "                      'optim_sd_decoder': model.decoder.optim.state_dict(),\n",
    "                      'train_history': train_history,\n",
    "                      'val_history': val_history\n",
    "                      }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(\"EPOCH [{}/{}] | Train Loss: {} | Val. Loss: {} | time: {}m {}s\".format(epoch+1,\n",
    "                                                                                           epochs,\n",
    "                                                                                           train_loss,\n",
    "                                                                                           val_loss,\n",
    "                                                                                           elapsed_mins,\n",
    "                                                                                          elapsed_secs))\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Test learning, input phrase: 'Hey how are you?'\")\n",
    "            if model.attention:\n",
    "                searcher = GreedySearch(encoder, decoder, vocabulary, attention=True).to(device)\n",
    "            else:\n",
    "                searcher = GreedySearch(encoder, decoder, vocabulary, attention=False).to(device)\n",
    "            run_bot(searcher, testing=True)\n",
    "    # save training model.\n",
    "    print('Training completed.')\n",
    "    torch.save(model.state_dict(), path_saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> hello\n",
      "i a years of\n",
      "> how are you\n",
      "i and between that s it day us\n",
      "> what do you do for living\n",
      "i\n",
      "> i what?\n",
      "i blimey are he chronic gardena with times so it\n",
      "> you seem confused\n",
      "i that were name people you bartered to last\n",
      "> ok bye\n",
      "you\n",
      "> quit\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Chatbot\n",
    "run_bot(searcher, testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_blue(searcher):\n",
    "    \"\"\"\n",
    "    This function computes the bleu score.\n",
    "    :return: the blue score\n",
    "    \"\"\"\n",
    "    smoothing_fn = bleu_score.SmoothingFunction()\n",
    "    score = 0\n",
    "    for idx, test_data in enumerate(test_dataloader):\n",
    "        question = torch.transpose(test_data[0], 0, 1).to(device)\n",
    "        answer = torch.transpose(test_data[1], 0, 1)\n",
    "        answer = answer[1:]\n",
    "        answer = answer.reshape(1, -1).tolist()[0]\n",
    "        output = searcher(question)\n",
    "        output = output[1:]\n",
    "        prediction = output.topk(1).indices.reshape(1, -1).tolist()[0]\n",
    "        prediction = convert_to_string(prediction)\n",
    "        answer = convert_to_string(answer)\n",
    "        answer = [answer.split()]\n",
    "        prediction = prediction.split()\n",
    "        score += bleu_score.sentence_bleu(answer, prediction, smoothing_function=smoothing_fn.method5, weights=(0.5, 0.5))\n",
    "        if idx % 2000 == 0:\n",
    "            print('Sentences processed: [{}/{}]'.format(idx+1, len(test_dataloader)))\n",
    "    return (score/len(test_dataloader))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model):\n",
    "    if model.attention:\n",
    "        checkpoint_path = os.path.join(os.curdir, 'saved_models/checkpoint.pth')\n",
    "        path_saved_model = os.path.join(os.curdir, 'saved_models/trained_model.pth')\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(os.curdir, 'saved_models/checkpoint_no_att.pth')\n",
    "        path_saved_model = os.path.join(os.curdir, 'saved_models/trained_model_no_att.pth')\n",
    "        # check if the model is already trained\n",
    "    if os.path.exists(path_saved_model):\n",
    "        # load state_dict\n",
    "        print('Trained model found. Loading...')\n",
    "        model.load_state_dict(torch.load(path_saved_model, map_location=torch.device(device)))\n",
    "        print('Model loaded.')\n",
    "    else:\n",
    "        # check if a training phase was already started\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            # load trained values\n",
    "            loaded_checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "            print('Checkpoint found. Restore from [{}/{}] epoch.'.format(loaded_checkpoint['epoch'], epochs))\n",
    "            # restore previous values\n",
    "            epoch_idx = loaded_checkpoint['epoch']\n",
    "            model.load_state_dict(loaded_checkpoint['model_sd'])\n",
    "            model.encoder.optim.load_state_dict(loaded_checkpoint['optim_sd_encoder'])\n",
    "            model.decoder.optim.load_state_dict(loaded_checkpoint['optim_sd_decoder'])\n",
    "\n",
    "def load_values(model):\n",
    "    if model.attention:\n",
    "        checkpoint_path = os.path.join(os.curdir, 'saved_models/checkpoint.pth')\n",
    "        path_saved_model = os.path.join(os.curdir, 'saved_models/trained_model.pth')\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(os.curdir, 'saved_models/checkpoint_no_att.pth')\n",
    "        path_saved_model = os.path.join(os.curdir, 'saved_models/trained_model_no_att.pth')\n",
    "    #load stored values\n",
    "    loaded_checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "    # retrieve train loss history\n",
    "    train_history = loaded_checkpoint['train_history']\n",
    "    val_history = loaded_checkpoint['val_history']\n",
    "    return train_history, val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model found. Loading...\n",
      "Model loaded.\n",
      "Trained model found. Loading...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "# init model with attention\n",
    "encoder_att, decoder_att, model_att = init_model(with_attention=True)\n",
    "searcher_att = GreedySearch(encoder, decoder, vocabulary, attention=True).to(device)\n",
    "# # init model with no attention\n",
    "encoder_noatt, decoder_noatt, model_noatt = init_model(with_attention=False)\n",
    "searcher_noatt = GreedySearch(encoder, decoder, vocabulary, attention=False).to(device)\n",
    "\n",
    "# load values for both models\n",
    "load_model(model_att)\n",
    "load_model(model_noatt)\n",
    "\n",
    "train_loss_att, val_loss_att = load_values(model_att)\n",
    "train_loss_noatt, val_loss_noatt = load_values(model_noatt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_train_val_loss(train_att, val_att, train_noatt, val_noatt):\n",
    "    experiments = [[train_att, val_att],[train_noatt, val_noatt]]\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for idx, data in enumerate(experiments):\n",
    "        plt.subplot(1, 2, idx+1)\n",
    "        plt.plot(data[0], label='Train Loss-{}Att'.format('' if idx == 0 else 'No'))\n",
    "        plt.plot(data[1], label='Val Loss-{}Att'.format('' if idx == 0 else 'No'))\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Train vs Val Loss {}'.format('with Attention' if idx == 0 else 'no Attention'))\n",
    "        plt.legend()\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_val_loss(train_loss_att, val_loss_att, train_loss_noatt, val_loss_noatt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model found. Loading...\n",
      "Model loaded.\n",
      "Sentences processed: [1/22149]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-16-d1d16dae8901>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mload_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m# compute blue score\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mblue_att\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_blue\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msearcher\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Blue score model with attention: {}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblue_att\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-11-5764aa343530>\u001B[0m in \u001B[0;36mcompute_blue\u001B[0;34m(searcher)\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msearcher\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquestion\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtopk\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m         \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_to_string\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprediction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_to_string\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# init model with attention\n",
    "encoder, decoder, model = init_model(with_attention=True)\n",
    "searcher = GreedySearch(encoder, decoder, vocabulary, attention=True).to(device)\n",
    "# load model\n",
    "load_model(model)\n",
    "# compute blue score\n",
    "blue_att = compute_blue(searcher)\n",
    "print('Blue score model with attention: {}'.format(blue_att))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model found. Loading...\n",
      "Model loaded.\n",
      "Sentences processed: [1/22149]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-1d5b779dae99>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#laod model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mload_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mblue_noatt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_blue\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msearcher\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Blue score model without attention: {}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblue_noatt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-11-5764aa343530>\u001B[0m in \u001B[0;36mcompute_blue\u001B[0;34m(searcher)\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msearcher\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquestion\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtopk\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/City/706/Coursework/Chatbot-Pytorch-INM706/model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_seq, max_length)\u001B[0m\n\u001B[1;32m    309\u001B[0m             \u001B[0;31m# compute the predictions through the decoder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mseq_len\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 311\u001B[0;31m                 \u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh_n\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc_n\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mword_t\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh_n\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc_n\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m                 \u001B[0moutputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m                 \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/City/706/Coursework/Chatbot-Pytorch-INM706/model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x, h, c)\u001B[0m\n\u001B[1;32m    102\u001B[0m         \u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mh\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlstm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0membedded_word\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mh\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 104\u001B[0;31m         \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfc_1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    105\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mpred\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     93\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 94\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     95\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1751\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1752\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1753\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1754\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1755\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# init model without attention\n",
    "encoder, decoder, model = init_model(with_attention=False)\n",
    "searcher = GreedySearch(encoder, decoder, vocabulary, attention=False).to(device)\n",
    "#laod model\n",
    "load_model(model)\n",
    "blue_noatt = compute_blue(searcher)\n",
    "print('Blue score model without attention: {}'.format(blue_noatt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}